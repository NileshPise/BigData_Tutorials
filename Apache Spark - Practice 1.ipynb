{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f964335b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/12/26 12:32:33 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9705acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pythonList = [1,2,3,4,5,6,7,8,9,10]\n",
    "pythonList2 = [('s1',1),('s2',2),('s1',3),('s4',4),('s2',5),('s4',6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96961357",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(pythonList, 2)\n",
    "rdd2 = sc.parallelize(pythonList2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a67488e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a839d393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', 1), ('s2', 2), ('s1', 3), ('s4', 4), ('s2', 5), ('s4', 6)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53a8476e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate sum\n",
    "rdd.aggregate((0,0), seqOp= (lambda local_part, local_length: (local_part[0] + local_length, local_part[1]+1)) \\\n",
    "              , combOp= (lambda total_local_part, total_local_length: (total_local_part[0] + total_local_length[0], \\\n",
    "                                                                      total_local_part[1] + total_local_length[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15073968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.aggregate(0, seqOp= (lambda data, data2: (data + data2)) \\\n",
    "              ,combOp= (lambda data, data2: (data + data2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a94fa31",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/28240706/explain-the-aggregate-functionality-in-spark-with-python-and-scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "31b1cc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 10)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average\n",
    "rdd.aggregate((0, 0), seqOp= (lambda local_part, local_length: ((local_part[0]+local_length), (local_part[1]+1))) \\\n",
    "              , combOp= (lambda totol_local_part, total_local_length: ((totol_local_part[0] + total_local_length[0]), \\\n",
    "                                                                       totol_local_part[1]+total_local_length[1]))) \\\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69af6fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.4453125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.aggregate(0, seqOp=(lambda data, data2: (data + data2)/2) \\\n",
    "             ,combOp=(lambda data, data2: (data + data2)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "357b088c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#min\n",
    "rdd.aggregate((1,0), seqOp=(lambda local_part, local_length: (min(local_part[0], local_length), local_part[1]+1)) \\\n",
    "             ,combOp=(lambda total_local_part,total_local_length: (min(total_local_part[0], total_local_length[0]), \\\n",
    "                                                                  total_local_part[1]+total_local_length[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d01b4846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.aggregate(50000000000000000000000000000000000000000000000000000000000000000000000,\n",
    "             seqOp= (lambda data, data2: min(data, data2)) \\\n",
    "             ,combOp=(lambda data, data2: min(data, data2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d689cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max\n",
    "rdd.aggregate((0,0), seqOp=(lambda local_part, local_length: (max(local_part[0], local_length), local_part[1]+1)) \\\n",
    "             ,combOp=(lambda total_local_part,total_local_length: (max(total_local_part[0], total_local_length[0]), \\\n",
    "                                                                  total_local_part[1]+total_local_length[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41f64698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.aggregate(0, seqOp=(lambda data, data2: max(data, data2)) \\\n",
    "             , combOp=(lambda data, data2: max(data, data2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d649c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregateby keys sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10d4690c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', 4), ('s2', 7), ('s4', 10)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.aggregateByKey(0, seqFunc=(lambda x,y: (x+y)), combFunc=(lambda z,c:(z+c))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ddc22cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', [4, 2]), ('s2', [7, 2]), ('s4', [10, 2])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.aggregateByKey((0,0),(lambda local_part, local_length: [local_part[0] + local_length, local_part[1]+1]) \\\n",
    "              ,(lambda total_local_part, total_local_length: [total_local_part[0] + total_local_length[0], \\\n",
    "                                                                      total_local_part[1] + total_local_length[1]])) \\\n",
    ".collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd83136f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', 2.0), ('s2', 3.5), ('s4', 5.0)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average\n",
    "rdd2.aggregateByKey((0,0), seqFunc=(lambda acc, part: [acc[0]+part, acc[1]+1]) \\\n",
    "                   ,combFunc=(lambda local_part, another_local_part: [local_part[0]+another_local_part[0] \\\n",
    "                                                                     ,local_part[1]+another_local_part[1]])) \\\n",
    ".map(lambda data: (data[0], data[1][0]/data[1][1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4fef793b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', 3), ('s2', 5), ('s4', 6)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max\n",
    "rdd2.aggregateByKey(0, seqFunc=(lambda acc, data:(max(acc,data))), \n",
    "                   combFunc=(lambda local_part, another_local_part: max(local_part, another_local_part))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2ce820eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', 1), ('s2', 2), ('s4', 4)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#min\n",
    "rdd2.aggregateByKey(10, seqFunc=(lambda acc, data:min(acc, data)),\n",
    "                   combFunc=(lambda acc, data: min(acc, data))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0449057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['filamentA', '100W', 605],\n",
       " ['filamentB', '100W', 683],\n",
       " ['filamentB', '100W', 691]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingle = [['filamentA','100W',605],\n",
    "                  ['filamentB','100W',683],\n",
    "                  ['filamentB','100W',691],\n",
    "                  ['filamentB','200W',561],\n",
    "                  ['filamentA','200W',530],\n",
    "                  ['filamentA','100W',619],\n",
    "                  ['filamentB','100W',686],\n",
    "                  ['filamentB','200W',600],\n",
    "                  ['filamentB','100W',696],\n",
    "                  ['filamentA','200W',579],\n",
    "                  ['filamentA','200W',520],\n",
    "                  ['filamentA','100W',622],\n",
    "                  ['filamentA','100W',668],\n",
    "                  ['filamentB','200W',569],\n",
    "                  ['filamentB','200W',555],\n",
    "                  ['filamentA','200W',541]]\n",
    "filDataSingleRDD = sc.parallelize(filDataSingle,2)\n",
    "filDataSingleRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "228addcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "complexRDD = filDataSingleRDD.map(lambda data: [(data[0], data[1]), data[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56b2bb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('filamentA', '100W'), 605], [('filamentB', '100W'), 683]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3c20b9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('filamentB', '100W'), 2756),\n",
       " (('filamentA', '200W'), 2170),\n",
       " (('filamentA', '100W'), 2514),\n",
       " (('filamentB', '200W'), 2285)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sum on complex rdd\n",
    "complexRDD.aggregateByKey(0, seqFunc=(lambda acc, data: acc+data),\n",
    "                         combFunc=(lambda local_part, another_local_part: local_part+another_local_part)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "68b56b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('filamentB', '100W'), 689.0],\n",
       " [('filamentA', '200W'), 542.5],\n",
       " [('filamentA', '100W'), 628.5],\n",
       " [('filamentB', '200W'), 571.25]]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average on complex rdd\n",
    "complexRDD.aggregateByKey((0,0), seqFunc=(lambda acc, data: [acc[0]+data, acc[1]+1]),\n",
    "                         combFunc=(lambda local_part, another_local_part: [local_part[0]+another_local_part[0] \\\n",
    "                                                                           , local_part[1]+another_local_part[1]])) \\\n",
    ".map(lambda data: [data[0], data[1][0]/data[1][1]]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "483cd9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('filamentB', '100W'), 683),\n",
       " (('filamentA', '200W'), 520),\n",
       " (('filamentA', '100W'), 605),\n",
       " (('filamentB', '200W'), 555)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#min on complex rdd\n",
    "complexRDD.aggregateByKey(50000, seqFunc=(lambda acc, data: min(acc, data)),\n",
    "                         combFunc=(lambda local_part, another_local_part: min(local_part, another_local_part))) \\\n",
    ".collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ffd4ed7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('filamentB', '100W'), 696),\n",
       " (('filamentA', '200W'), 579),\n",
       " (('filamentA', '100W'), 668),\n",
       " (('filamentB', '200W'), 600)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max on complex rdd\n",
    "complexRDD.aggregateByKey(0, seqFunc=lambda acc, data: max(acc, data),\n",
    "                         combFunc=lambda local_part, another_local_part: max(local_part, another_local_part)) \\\n",
    ".collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a404b848",
   "metadata": {},
   "source": [
    "### Cache\n",
    "\n",
    "PySpark cache() method is used to cache the intermediate results of the transformation into memory so that any future transformations on the results of cached transformation improve the performance. Caching is a lazy evaluation meaning it will not cache the results until you call the action operation and the result of the transformation is one of the optimization tricks to improve the performance of the long-running PySpark applications/jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0b096",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/38581809/what-is-the-purpose-of-cache-an-rdd-in-apache-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b5d126b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', 1), ('s2', 2), ('s1', 3), ('s4', 4), ('s2', 5), ('s4', 6)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4f0e01fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', 1), ('s2', 2), ('s1', 3), ('s4', 4), ('s2', 5), ('s4', 6)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.cache().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2ac9a451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', 1), ('s2', 2), ('s1', 3), ('s4', 4), ('s2', 5), ('s4', 6)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea9b59c",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.cartesian\n",
    "\n",
    "cartesian() in RDD will return the new RDD that includes all the elements from both the RDDs. It returns a cartesian product such that each element in the first RDD is combined with all elements from the second RDD in the form of a pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3f9c4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd5 = sc.parallelize([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1980206e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (1, 2), (1, 3), (2, 1), (3, 1), (2, 2), (2, 3), (3, 2), (3, 3)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5.cartesian(rdd5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5aa94604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.cartesian(rdd5).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a442121",
   "metadata": {},
   "source": [
    "#### RDD CheckPointing\n",
    "Mark this RDD for checkpointing. It will be saved to a file inside the checkpoint directory set with SparkContext.setCheckpointDir() and all references to its parent RDDs will be removed. This function must be called before any job has been executed on this RDD. It is strongly recommended that this RDD is persisted in memory, otherwise saving it on a file will require recomputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "74e3b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/24 15:59:53 WARN SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/user/spark_checkpointing/' appears to be on the local filesystem.\n"
     ]
    }
   ],
   "source": [
    "sc.setCheckpointDir('/user/spark_checkpointing/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5f37015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd5.checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3a45ae6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5.is_checkpointed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fd0d20",
   "metadata": {},
   "source": [
    "https://livebook.manning.com/book/spark-in-action-with-examples-in-java/16-cache-and-checkpoint-enhancing-spark-s-performances/v-14/50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b77b31",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "31e177d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4], [5, 6], [7, 8, 9, 10]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1,2,3,4,5,6,7,8,9,10],4)\n",
    "rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f0776617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a7ae212f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.coalesce(1).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "484549d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = rdd.coalesce(1)\n",
    "rdd1.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c05d0a",
   "metadata": {},
   "source": [
    "\n",
    "#### Spark Repartition() vs Coalesce()\n",
    "\n",
    "\n",
    "Spark repartition() vs coalesce() – repartition() is used to increase or decrease the RDD, DataFrame, Dataset partitions whereas the coalesce() is used to only decrease the number of partitions in an efficient way.\n",
    "\n",
    "In this article, you will learn what is Spark repartition() and coalesce() methods? and the difference between repartition vs coalesce with Scala examples.\n",
    "\n",
    "NOTE: One important point to note is, Spark repartition() and coalesce() are very expensive operations as they shuffle the data across many partitions hence try to minimize repartition as much as possible.\n",
    "#### Spark RDD repartition() vs coalesce()\n",
    "\n",
    "In RDD, you can create parallelism at the time of the creation of an RDD using parallelize(), textFile() and wholeTextFiles(). You can download the test.txt file used in this example from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "08dd29ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd10 = sc.parallelize([i for i in range(0,100)], 4)\n",
    "rdd10.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "72e2728a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74], [75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]\n"
     ]
    }
   ],
   "source": [
    "print(rdd10.glom().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a650829",
   "metadata": {},
   "source": [
    "#### RDD repartition()\n",
    "\n",
    "Spark RDD repartition() method is used to increase or decrease the partitions. The below example decreases the partitions from 10 to 4 by moving data from all partitions.\n",
    "\n",
    "\n",
    "This yields output Repartition size : 4 and the repartition re-distributes the data(as shown below) from all partitions which is full shuffle leading to very expensive operation when dealing with billions and trillions of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d5c4ed28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = rdd10.repartition(3)\n",
    "rdd2.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa50be2e",
   "metadata": {},
   "source": [
    "#### RDD coalesce()\n",
    "\n",
    "Spark RDD coalesce() is used only to reduce the number of partitions. This is optimized or improved version of repartition() where the movement of the data across the partitions is lower using coalesce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "07d550f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20, 21, 22, 23, 24, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 70, 71, 72, 73, 74, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 95, 96, 97, 98, 99], [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]]\n"
     ]
    }
   ],
   "source": [
    "print(rdd2.glom().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2c828368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd11 = rdd10.coalesce(2)\n",
    "rdd11.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ffab85",
   "metadata": {},
   "source": [
    "If you compared the below output with section 1, you will notice partition 3 has been moved to 2 and Partition 6 has moved to 5, resulting data movement from just 2 partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fb272021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', ([1], [2])), ('b', ([4], []))]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Cogroup\n",
    "x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
    "y = sc.parallelize([(\"a\", 2)])\n",
    "[(x, tuple(map(list, y))) for x, y in sorted(list(x.cogroup(y).collect()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "864fe11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1], [2])\n",
      "([4], [])\n"
     ]
    }
   ],
   "source": [
    "for x, y in sorted(list(x.cogroup(y).collect())):\n",
    "    print((tuple(map(list,y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1a947",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.collectAsMap\n",
    "This method should only be used if the resulting data is expected to be small, as all the data is loaded into the driver’s memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f5e006f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sc.parallelize([(1, 2), (3, 4)]).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "032d0ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2, 3: 4}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "37cffffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1718aed",
   "metadata": {},
   "source": [
    "In case of duplicate keys\n",
    "\n",
    "When we have duplicate keys, the latter key-value pair will overwrite the former ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "57f5ad30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2, 3: 19}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/24 17:35:47 WARN HeartbeatReceiver: Removing executor 1 with no recent heartbeats: 131537 ms exceeds timeout 120000 ms\n",
      "22/12/24 17:37:47 ERROR Utils: Uncaught exception in thread kill-executor-thread\n",
      "org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)\n",
      "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.killExecutors(CoarseGrainedSchedulerBackend.scala:890)\n",
      "\tat org.apache.spark.SparkContext.killAndReplaceExecutor(SparkContext.scala:1825)\n",
      "\tat org.apache.spark.HeartbeatReceiver$$anon$2.$anonfun$run$2(HeartbeatReceiver.scala:214)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)\n",
      "\tat org.apache.spark.HeartbeatReceiver$$anon$2.run(HeartbeatReceiver.scala:211)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:293)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\t... 10 more\n",
      "22/12/24 17:37:47 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending KillExecutors(List(1)) to AM was unsuccessful\n",
      "org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from /192.168.87.202:57610 in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat scala.util.Failure.recover(Try.scala:234)\n",
      "\tat scala.concurrent.Future.$anonfun$recover$1(Future.scala:395)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.tryFailure(Promise.scala:112)\n",
      "\tat scala.concurrent.Promise.tryFailure$(Promise.scala:112)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:264)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from /192.168.87.202:57610 in 120 seconds\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:265)\n",
      "\t... 7 more\n",
      "22/12/24 17:37:47 WARN NettyRpcEnv: Ignored failure: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from /192.168.87.202:57610 in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n",
      "22/12/24 17:43:06 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 141. The executor 1 may have been lost.\n",
      "org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from /192.168.87.202:44050 in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat scala.util.Failure.recover(Try.scala:234)\n",
      "\tat scala.concurrent.Future.$anonfun$recover$1(Future.scala:395)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.tryFailure(Promise.scala:112)\n",
      "\tat scala.concurrent.Promise.tryFailure$(Promise.scala:112)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:264)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from /192.168.87.202:44050 in 120 seconds\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:265)\n",
      "\t... 7 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/24 17:45:06 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 140. The executor 1 may have been lost.\n",
      "org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from /192.168.87.202:44050 in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat scala.util.Failure.recover(Try.scala:234)\n",
      "\tat scala.concurrent.Future.$anonfun$recover$1(Future.scala:395)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.tryFailure(Promise.scala:112)\n",
      "\tat scala.concurrent.Promise.tryFailure$(Promise.scala:112)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:264)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from /192.168.87.202:44050 in 120 seconds\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:265)\n",
      "\t... 7 more\n",
      "22/12/24 17:47:06 WARN BlockManagerMasterEndpoint: Error trying to remove shuffle 50. The executor 1 may have been lost.\n",
      "org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from /192.168.87.202:44050 in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat scala.util.Failure.recover(Try.scala:234)\n",
      "\tat scala.concurrent.Future.$anonfun$recover$1(Future.scala:395)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.tryFailure(Promise.scala:112)\n",
      "\tat scala.concurrent.Promise.tryFailure$(Promise.scala:112)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:264)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from /192.168.87.202:44050 in 120 seconds\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:265)\n",
      "\t... 7 more\n",
      "22/12/24 17:47:06 WARN BlockManagerMasterEndpoint: Error trying to remove shuffle 48. The executor 1 may have been lost.\n",
      "org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from /192.168.87.202:44050 in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat scala.util.Failure.recover(Try.scala:234)\n",
      "\tat scala.concurrent.Future.$anonfun$recover$1(Future.scala:395)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.tryFailure(Promise.scala:112)\n",
      "\tat scala.concurrent.Promise.tryFailure$(Promise.scala:112)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:264)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from /192.168.87.202:44050 in 120 seconds\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:265)\n",
      "\t... 7 more\n",
      "22/12/24 17:47:06 WARN BlockManagerMasterEndpoint: Error trying to remove shuffle 40. The executor 1 may have been lost.\n",
      "org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from /192.168.87.202:44050 in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat scala.util.Failure.recover(Try.scala:234)\n",
      "\tat scala.concurrent.Future.$anonfun$recover$1(Future.scala:395)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.tryFailure(Promise.scala:112)\n",
      "\tat scala.concurrent.Promise.tryFailure$(Promise.scala:112)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:264)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from /192.168.87.202:44050 in 120 seconds\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:265)\n",
      "\t... 7 more\n",
      "22/12/24 17:47:06 WARN BlockManagerMasterEndpoint: Error trying to remove shuffle 49. The executor 1 may have been lost.\n",
      "org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from /192.168.87.202:44050 in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat scala.util.Failure.recover(Try.scala:234)\n",
      "\tat scala.concurrent.Future.$anonfun$recover$1(Future.scala:395)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.tryFailure(Promise.scala:112)\n",
      "\tat scala.concurrent.Promise.tryFailure$(Promise.scala:112)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:264)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from /192.168.87.202:44050 in 120 seconds\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:265)\n",
      "\t... 7 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/24 17:49:25 ERROR YarnClientSchedulerBackend: YARN application has exited unexpectedly with state FAILED! Check the YARN application logs for more details.\n",
      "22/12/24 17:49:25 ERROR YarnClientSchedulerBackend: Diagnostics message: Uncaught exception: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.deploy.yarn.ApplicationMaster.runExecutorLauncher(ApplicationMaster.scala:558)\n",
      "\tat org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:277)\n",
      "\tat org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:926)\n",
      "\tat org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:925)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)\n",
      "\tat org.apache.spark.deploy.yarn.ExecutorLauncher$.main(ApplicationMaster.scala:957)\n",
      "\tat org.apache.spark.deploy.yarn.ExecutorLauncher.main(ApplicationMaster.scala)\n",
      "Caused by: java.io.IOException: Failed to connect to audacious/192.168.115.202:36285\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:288)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)\n",
      "\tat org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)\n",
      "\tat org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: audacious/192.168.115.202:36285\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n",
      "\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:710)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "22/12/24 17:51:25 ERROR Utils: Uncaught exception in thread YARN application state monitor\n",
      "org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)\n",
      "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.requestTotalExecutors(CoarseGrainedSchedulerBackend.scala:789)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnSchedulerBackend.stop(YarnSchedulerBackend.scala:114)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.stop(YarnClientSchedulerBackend.scala:178)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:931)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2785)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$11(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:125)\n",
      "Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:293)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\t... 9 more\n",
      "22/12/24 17:51:25 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(Map(),Map(),Map(),Set()) to AM was unsuccessful\n",
      "org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from /192.168.87.202:57610 in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat scala.util.Failure.recover(Try.scala:234)\n",
      "\tat scala.concurrent.Future.$anonfun$recover$1(Future.scala:395)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.tryFailure(Promise.scala:112)\n",
      "\tat scala.concurrent.Promise.tryFailure$(Promise.scala:112)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:264)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from /192.168.87.202:57610 in 120 seconds\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:265)\n",
      "\t... 7 more\n",
      "22/12/24 17:51:25 WARN NettyRpcEnv: Ignored failure: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from /192.168.87.202:57610 in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n"
     ]
    }
   ],
   "source": [
    "m = sc.parallelize([(1, 2), (3, 4),(3, 19)]).collectAsMap()\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a9861e",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.collect\n",
    "This method should only be used if the resulting data is expected to be small, as all the data is loaded into the driver’s memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9c400739",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sc.parallelize([(1, 2), (3, 4)]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "05b079d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (3, 4)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3a8e2d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3d9f43",
   "metadata": {},
   "source": [
    "https://www.skytowner.com/explore/pyspark_dataframe_alias_method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3277b52",
   "metadata": {},
   "source": [
    "#### CombineByKey\n",
    "\n",
    "Generic function to combine the elements for each key using a custom set of aggregation functions.\n",
    "\n",
    "Turns an RDD[(K, V)] into a result of type RDD[(K, C)], for a “combined type” C.\n",
    "\n",
    "Users provide three functions:\n",
    "\n",
    "        createCombiner, which turns a V into a C (e.g., creates a one-element list)\n",
    "\n",
    "        mergeValue, to merge a V into a C (e.g., adds it to the end of a list)\n",
    "\n",
    "        mergeCombiners, to combine two C’s into a single one (e.g., merges the lists)\n",
    "\n",
    "To avoid memory allocation, both mergeValue and mergeCombiners are allowed to modify and return their first argument instead of creating a new C.\n",
    "\n",
    "In addition, users can control the partitioning of the output RDD.\n",
    "\n",
    "\n",
    "#### Spark PairRDDFunctions: CombineByKey\n",
    "\n",
    "\n",
    "Last time we covered one of the alternatives to the groupByKey function aggregateByKey. In this post we’ll cover another alternative PairRDDFunction – combineByKey. The combineByKey function is similar in functionality to the aggregateByKey function, but is more general. But before we go into details let’s review why we’d even want to avoid using groupByKey. When working in a map-reduce framework such Spark or Hadoop one of the steps we can take to ensure maximum performance is to limit the amount of data sent accross the network during the shuffle phase. The best option is when all operations can be performed on the map-side exclusively, meaning no data is sent at all to reducers. In most cases though, it’s not going to be realistic to do map-side operations only. If you need to do any sort of grouping, sorting or aggregation you’ll need to send data to reducers. But that doesn’t mean we still can’t attempt to make some optimizations.\n",
    "GroupByKey Is Expensive\n",
    "\n",
    "In the case of a groupByKey call, every single key-value pair will be shuffled accross the network with identical keys landing on the same reducer. To state the obvious, when grouping by key, the need for all matching keys to end up on the same reducer can’t be avoided. But one optimization we can attempt is to combine/merge values so we end up sending fewer key-value pairs in total. Addtionaly, less key-value pairs means reducers won’t have as much work to do, leading to additional performance gains. The groupByKey call makes no attempt at merging/combining values, so it’s an expensive operation.\n",
    "CombineByKey\n",
    "\n",
    "The combineByKey call is just such an optimization. When using combineByKey values are merged into one value at each partition then each partition value is merged into a single value. It’s worth noting that the type of the combined value does not have to match the type of the original value and often times it won’t be. The combineByKey function takes 3 functions as arguments:\n",
    "\n",
    "A function that creates a combiner. In the aggregateByKey function the first argument was simply an initial zero value. In combineByKey we provide a function that will accept our current value as a parameter and return our new value that will be merged with addtional values.\n",
    "\n",
    "The second function is a merging function that takes a value and merges/combines it into the previously collecte value(s).\n",
    "\n",
    "The third function combines the merged values together. Basically this function takes the new values produced at the partition level and combines them until we end up with one singular value.\n",
    "\n",
    "\n",
    "https://www.linkedin.com/pulse/spark-pyspark-combinebykey-simplified-swadeep-mishra-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55e38840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 1), ('a', 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 2)])\n",
    "x.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a951a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_list(a):\n",
    "    return [a]\n",
    "\n",
    "\n",
    "def append(a, b):\n",
    "    a.append(b)\n",
    "    return a\n",
    "\n",
    "\n",
    "def extend(a, b):\n",
    "    a.extend(b)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "375d7957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('a', [1, 2]), ('b', [1])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(x.combineByKey(to_list, append, extend).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75c05091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print([1,2,3].extend([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e3f8863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('filamentA', '100W'), 605], [('filamentB', '100W'), 683]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ddaf6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('filamentB', '100W'), (2756, 4)),\n",
       " (('filamentA', '200W'), (2170, 4)),\n",
       " (('filamentA', '100W'), (2514, 4)),\n",
       " (('filamentB', '200W'), (2285, 4))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Combinebykey sum\n",
    "complexRDD.combineByKey(createCombiner=(lambda data: (data, 1)) \\\n",
    "                              , mergeValue=(lambda acc, data:(acc[0]+data, acc[1]+1)) \\\n",
    "                             ,mergeCombiners=(lambda data, data2:((data[0]+data2[0]), data[1]+data2[1]))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fdec0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('filamentB', '100W'), 2756),\n",
       " (('filamentA', '200W'), 2170),\n",
       " (('filamentA', '100W'), 2514),\n",
       " (('filamentB', '200W'), 2285)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Combinebykey sum\n",
    "complexRDD.combineByKey(createCombiner=(lambda data: (data)) \\\n",
    "                       ,mergeValue=(lambda acc, data:(acc+data)) \\\n",
    "                       ,mergeCombiners=(lambda data, data2:(data+data2))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1aabf133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('filamentB', '100W'), 689.0),\n",
       " (('filamentA', '200W'), 542.5),\n",
       " (('filamentA', '100W'), 628.5),\n",
       " (('filamentB', '200W'), 571.25)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## combinebykey avg\n",
    "complexRDD.combineByKey(createCombiner=(lambda data:(data, 1)) \\\n",
    "                       ,mergeValue=(lambda acc, data:(acc[0]+data, acc[1]+1)) \\\n",
    "                       ,mergeCombiners=(lambda data, data2:((data[0]+data2[0])/(data[1]+data2[1])))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "880cc45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('filamentB', '100W'), 683),\n",
       " (('filamentA', '200W'), 520),\n",
       " (('filamentA', '100W'), 605),\n",
       " (('filamentB', '200W'), 555)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## combinebykey min\n",
    "complexRDD.combineByKey(createCombiner=(lambda data:data) \\\n",
    "                       ,mergeValue=(lambda acc, data:(min(acc, data))) \\\n",
    "                       ,mergeCombiners=(lambda data, data2: min(data, data2))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be51b1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('filamentB', '100W'), 696),\n",
       " (('filamentA', '200W'), 579),\n",
       " (('filamentA', '100W'), 668),\n",
       " (('filamentB', '200W'), 600)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##combinebykey max\n",
    "complexRDD.combineByKey(createCombiner=(lambda data:data) \\\n",
    "                       ,mergeValue=(lambda acc, data:max(acc, data)) \\\n",
    "                       ,mergeCombiners=(lambda data, data2: max(data, data2))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1eaf75",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.context\n",
    "\n",
    "The SparkContext that this RDD was created on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c78f9d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://audacious:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=pyspark-shell>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexRDD.context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45794858",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.count\n",
    "\n",
    "Return the number of elements in this RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05b5fa13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f89dcb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([1,2,3])\n",
    "x.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc81205a",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.countApprox\n",
    "\n",
    "Approximate version of count() that returns a potentially incomplete result within a timeout, even if not all tasks have finished.\n",
    "\n",
    "Now coming back to the question of count() vs countApprox(). Count is just like doing a select count(*) from Table. countApprox can have a timeout and confidence level which returns back a result which is approximately correct and a number you can live with.\n",
    "\n",
    "We should use countApprox when we are more interested in knowing an approximate number and save time for example in a streaming application. Count() should be used when you need the exact count for example to log something or for auditing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be37433c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:========================================>                 (7 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:====================================================>     (9 + 1) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize(range(1000),10)\n",
    "print(x.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c9f3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:====================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.countApprox(timeout=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aba8308",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.countApproxDistinct¶\n",
    "\n",
    "Return approximate number of distinct elements in the RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a374fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1006"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.countApproxDistinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bb61bc",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.countByKey\n",
    "Count the number of elements for each key, and return the result to the master as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa3dde55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 1), ('a', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b55efe81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 2, 'b': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a51897a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.countByKey()['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f6f71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 2), ('b', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(rdd.countByKey().items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64db46f",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.countByValue\n",
    "Return the count of each unique value in this RDD as a dictionary of (value, count) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13f6cc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {('a', 1): 2, ('b', 1): 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b05d057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 3, 1, 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([1,2,3,1,3,1,3])\n",
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac053b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(1, 3), (2, 1), (3, 3)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.countByValue().items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9974193a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3), (2, 1), (3, 3)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(rdd1.countByValue().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cb18efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3), (2, 1), (3, 3)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(sorted(rdd1.countByValue().items())).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e2655",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.distinct\n",
    "Return a new RDD containing the distinct elements in this RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeecca67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "995f0e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b295164f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92b9b6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['filamentA', '100W', 605],\n",
       " ['filamentB', '100W', 683],\n",
       " ['filamentB', '100W', 691],\n",
       " ['filamentB', '200W', 561],\n",
       " ['filamentA', '200W', 530],\n",
       " ['filamentA', '100W', 619],\n",
       " ['filamentB', '100W', 686],\n",
       " ['filamentB', '200W', 600],\n",
       " ['filamentB', '100W', 696],\n",
       " ['filamentA', '200W', 579],\n",
       " ['filamentA', '200W', 520],\n",
       " ['filamentA', '100W', 622],\n",
       " ['filamentA', '100W', 668],\n",
       " ['filamentB', '200W', 569],\n",
       " ['filamentB', '200W', 555],\n",
       " ['filamentA', '200W', 541]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af26ecc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ad25726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('100W', 605),\n",
       " ('100W', 683),\n",
       " ('100W', 691),\n",
       " ('200W', 561),\n",
       " ('200W', 530),\n",
       " ('100W', 619),\n",
       " ('100W', 686),\n",
       " ('200W', 600),\n",
       " ('100W', 696),\n",
       " ('200W', 579),\n",
       " ('200W', 520),\n",
       " ('100W', 622),\n",
       " ('100W', 668),\n",
       " ('200W', 569),\n",
       " ('200W', 555),\n",
       " ('200W', 541)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairedrdd = filDataSingleRDD.map(lambda data:(data[1],data[2]))\n",
    "pairedrdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36e660fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('200W', 561),\n",
       " ('100W', 686),\n",
       " ('100W', 696),\n",
       " ('200W', 579),\n",
       " ('100W', 622),\n",
       " ('100W', 668),\n",
       " ('200W', 569),\n",
       " ('200W', 555),\n",
       " ('200W', 541),\n",
       " ('100W', 605),\n",
       " ('100W', 683),\n",
       " ('100W', 691),\n",
       " ('200W', 530),\n",
       " ('100W', 619),\n",
       " ('200W', 600),\n",
       " ('200W', 520)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairedrdd.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2acdf9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairedrdd.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78e0b5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/25 15:19:14 WARN TaskSetManager: Lost task 0.0 in stage 43.0 (TID 136) (audacious executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/worker.py\", line 686, in main\n",
      "    process()\n",
      "  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/worker.py\", line 676, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 3472, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 3472, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 540, in func\n",
      "    return f(iterator)\n",
      "  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 2554, in combineLocally\n",
      "    merger.mergeValues(iterator)\n",
      "  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/shuffle.py\", line 255, in mergeValues\n",
      "    d[k] = comb(d[k], v) if k in d else creator(v)\n",
      "TypeError: unhashable type: 'list'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:765)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:747)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n",
      "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "22/12/25 15:19:15 ERROR TaskSetManager: Task 0 in stage 43.0 failed 4 times; aborting job\n",
      "22/12/25 15:19:15 WARN TaskSetManager: Lost task 1.3 in stage 43.0 (TID 143) (audacious executor 1): TaskKilled (Stage cancelled)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 43.0 failed 4 times, most recent failure: Lost task 0.3 in stage 43.0 (TID 142) (audacious executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/worker.py\", line 686, in main\n    process()\n  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/worker.py\", line 676, in process\n    out_iter = func(split_index, iterator)\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 3472, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 3472, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 540, in func\n    return f(iterator)\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 2554, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/shuffle.py\", line 255, in mergeValues\n    d[k] = comb(d[k], v) if k in d else creator(v)\nTypeError: unhashable type: 'list'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:765)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:747)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1020)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor43.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/worker.py\", line 686, in main\n    process()\n  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/worker.py\", line 676, in process\n    out_iter = func(split_index, iterator)\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 3472, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 3472, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 540, in func\n    return f(iterator)\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 2554, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/shuffle.py\", line 255, in mergeValues\n    d[k] = comb(d[k], v) if k in d else creator(v)\nTypeError: unhashable type: 'list'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:765)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:747)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_120524/2948623990.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomplexRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 43.0 failed 4 times, most recent failure: Lost task 0.3 in stage 43.0 (TID 142) (audacious executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/worker.py\", line 686, in main\n    process()\n  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/worker.py\", line 676, in process\n    out_iter = func(split_index, iterator)\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 3472, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 3472, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 540, in func\n    return f(iterator)\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 2554, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/shuffle.py\", line 255, in mergeValues\n    d[k] = comb(d[k], v) if k in d else creator(v)\nTypeError: unhashable type: 'list'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:765)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:747)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1020)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor43.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/worker.py\", line 686, in main\n    process()\n  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/worker.py\", line 676, in process\n    out_iter = func(split_index, iterator)\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 3472, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 3472, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 540, in func\n    return f(iterator)\n  File \"/home/audacious/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 2554, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/tmp/hadoop-audacious/nm-local-dir/usercache/audacious/appcache/application_1671801536838_0006/container_1671801536838_0006_01_000002/pyspark.zip/pyspark/shuffle.py\", line 255, in mergeValues\n    d[k] = comb(d[k], v) if k in d else creator(v)\nTypeError: unhashable type: 'list'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:765)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:747)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# distinct will not work on complex rdd and just created rdd it will worked on paired rdd\n",
    "complexRDD.distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730c408b",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.filter\n",
    "Return a new RDD containing only the elements that satisfy a predicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c1d8f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1,2,3,4,5,6,7,8,9,10], 2)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6df4025b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda data: data > 5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7e89d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda data: data%2 == 0).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "070160a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda data: data<0).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "584c2978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'hellos', 'okay no problem', 'yes yes']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringrdd = sc.parallelize(['hi', 'hellos','okay no problem', 'yes yes'])\n",
    "stringrdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c634fb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hellos', 'okay no problem', 'yes yes']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringrdd.filter(lambda data: len(data) > 5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91857741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringrdd.filter(lambda data: len(data) < 5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3390210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'hellos']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringrdd.filter(lambda data: 'h' in data).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6ac2200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hellos', 'yes yes']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringrdd.filter(lambda data: 's' in data).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccb9e464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('100W', 605),\n",
       " ('100W', 683),\n",
       " ('100W', 691),\n",
       " ('200W', 561),\n",
       " ('200W', 530),\n",
       " ('100W', 619),\n",
       " ('100W', 686),\n",
       " ('200W', 600),\n",
       " ('100W', 696),\n",
       " ('200W', 579),\n",
       " ('200W', 520),\n",
       " ('100W', 622),\n",
       " ('100W', 668),\n",
       " ('200W', 569),\n",
       " ('200W', 555),\n",
       " ('200W', 541)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairedrdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67e9aaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', 605),\n",
       " ('filamentB', 683),\n",
       " ('filamentB', 691),\n",
       " ('filamentB', 561),\n",
       " ('filamentA', 530),\n",
       " ('filamentA', 619),\n",
       " ('filamentB', 686),\n",
       " ('filamentB', 600),\n",
       " ('filamentB', 696),\n",
       " ('filamentA', 579),\n",
       " ('filamentA', 520),\n",
       " ('filamentA', 622),\n",
       " ('filamentA', 668),\n",
       " ('filamentB', 569),\n",
       " ('filamentB', 555),\n",
       " ('filamentA', 541)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairedrdd2 = filDataSingleRDD.map(lambda data:(data[0],data[2]))\n",
    "pairedrdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "803fd92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('100W', 605),\n",
       " ('100W', 683),\n",
       " ('100W', 691),\n",
       " ('100W', 619),\n",
       " ('100W', 686),\n",
       " ('100W', 696),\n",
       " ('100W', 622),\n",
       " ('100W', 668)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairedrdd.filter(lambda data: data[0] == '100W').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "807eee99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('100W', 683), ('100W', 691), ('100W', 686), ('100W', 696), ('100W', 668)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairedrdd.filter(lambda data: (data[0] == '100W') and (data[1] > 650)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27ef83c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['filamentA', '200W', 530],\n",
       " ['filamentA', '200W', 520],\n",
       " ['filamentA', '200W', 541]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.filter(lambda data:((data[0] =='filamentB') or (data[1] == '200W')) and (data[2] < 550)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6b36b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('filamentA', '200W'), 520]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexRDD.filter(lambda data: (data[0][0]=='filamentA') and (data[1]<530)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff11ce71",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.first\n",
    "Return the first element in this RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39e8b81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe7f9e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', '100W'), 605]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23a9dff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('100W', 605)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairedrdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ca813a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map \n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b669be0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda data: data*2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ba5443c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda data: data/2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "269b89f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda data: data+10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f18131e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi - 1',\n",
       " 'Hi - 2',\n",
       " 'Hi - 3',\n",
       " 'Hi - 4',\n",
       " 'Hi - 5',\n",
       " 'Hi - 6',\n",
       " 'Hi - 7',\n",
       " 'Hi - 8',\n",
       " 'Hi - 9',\n",
       " 'Hi - 10']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda data: \"Hi - {}\".format(data)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a6cbfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hi', 2), ('hellos', 6), ('okay no problem', 15), ('yes yes', 7)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringrdd.map(lambda data: (data, len(data))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1ee37b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'ellos', 'kay no problem', 'es yes']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringrdd.map(lambda data: data[1:]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45154abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hi'], ['hellos'], ['okay', 'no', 'problem'], ['yes', 'yes']]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringrdd.map(lambda data: data.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35f3a0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('filamentA', '100W'), 605],\n",
       " [('filamentB', '100W'), 683],\n",
       " [('filamentB', '100W'), 691],\n",
       " [('filamentB', '200W'), 561],\n",
       " [('filamentA', '200W'), 530],\n",
       " [('filamentA', '100W'), 619],\n",
       " [('filamentB', '100W'), 686],\n",
       " [('filamentB', '200W'), 600],\n",
       " [('filamentB', '100W'), 696],\n",
       " [('filamentA', '200W'), 579],\n",
       " [('filamentA', '200W'), 520],\n",
       " [('filamentA', '100W'), 622],\n",
       " [('filamentA', '100W'), 668],\n",
       " [('filamentB', '200W'), 569],\n",
       " [('filamentB', '200W'), 555],\n",
       " [('filamentA', '200W'), 541]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.map(lambda data: [(data[0], data[1]),data[2]]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940046f2",
   "metadata": {},
   "source": [
    "#### PySpark flatMap() Transformation\n",
    "\n",
    "PySpark flatMap() is a transformation operation that flattens the RDD/DataFrame (array/map DataFrame columns) after applying the function on every element and returns a new PySpark RDD/DataFrame. In this article, you will learn the syntax and usage of the PySpark flatMap() with an example.\n",
    "Now, let’s see with an example of how to apply a flatMap() transformation on RDD. In the below example, first, it splits each record by space in an RDD and finally flattens it. Resulting RDD consists of a single word on each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3abed970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'hellos', 'okay no problem', 'yes yes']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringrdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8c26df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hi'], ['hellos'], ['okay', 'no', 'problem'], ['yes', 'yes']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringrdd.map(lambda data: data.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c28b5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'hellos', 'okay', 'no', 'problem', 'yes', 'yes']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringrdd.flatMap(lambda data: data.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ccef33e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['filamentA', '100W', 605], ['filamentB', '100W', 683]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bfd5cb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filamentA',\n",
       " '100W',\n",
       " 'filamentB',\n",
       " '100W',\n",
       " 'filamentB',\n",
       " '100W',\n",
       " 'filamentB',\n",
       " '200W',\n",
       " 'filamentA',\n",
       " '200W',\n",
       " 'filamentA',\n",
       " '100W',\n",
       " 'filamentB',\n",
       " '100W',\n",
       " 'filamentB',\n",
       " '200W',\n",
       " 'filamentB',\n",
       " '100W',\n",
       " 'filamentA',\n",
       " '200W',\n",
       " 'filamentA',\n",
       " '200W',\n",
       " 'filamentA',\n",
       " '100W',\n",
       " 'filamentA',\n",
       " '100W',\n",
       " 'filamentB',\n",
       " '200W',\n",
       " 'filamentB',\n",
       " '200W',\n",
       " 'filamentA',\n",
       " '200W']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.flatMap(lambda data: [data[0], data[1]]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d124bfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filamentA',\n",
       " 605,\n",
       " 'filamentB',\n",
       " 683,\n",
       " 'filamentB',\n",
       " 691,\n",
       " 'filamentB',\n",
       " 561,\n",
       " 'filamentA',\n",
       " 530,\n",
       " 'filamentA',\n",
       " 619,\n",
       " 'filamentB',\n",
       " 686,\n",
       " 'filamentB',\n",
       " 600,\n",
       " 'filamentB',\n",
       " 696,\n",
       " 'filamentA',\n",
       " 579,\n",
       " 'filamentA',\n",
       " 520,\n",
       " 'filamentA',\n",
       " 622,\n",
       " 'filamentA',\n",
       " 668,\n",
       " 'filamentB',\n",
       " 569,\n",
       " 'filamentB',\n",
       " 555,\n",
       " 'filamentA',\n",
       " 541]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.flatMap(lambda data: [data[0], data[2]]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a840a7",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.flatMapValues\n",
    "Pass each value in the key-value pair RDD through a flatMap function without changing the keys; this also retains the original RDD’s partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d806c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', ['x', 'y', 'z']), ('b', ['p', 'r'])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([(\"a\", [\"x\", \"y\", \"z\"]), (\"b\", [\"p\", \"r\"])])\n",
    "x.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc1c3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'x'), ('a', 'y'), ('a', 'z'), ('b', 'p'), ('b', 'r')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.flatMapValues(lambda data: data).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a843990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', ['x', 'y', 'z'], 'b', ['p', 'r']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.flatMap(lambda data: data).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ec355",
   "metadata": {},
   "source": [
    "#### fold\n",
    "In this tutorial, you will learn fold syntax, usage and how to use Spark RDD fold() function in order to calculate min, max, and a total of the elements\n",
    "\n",
    "Since RDD’s are partitioned, the fold() function takes full advantage of it by first aggregating elements in each partition and then aggregating results of all partitions to get the final result. The result of this function is the same as this RDD type.\n",
    "\n",
    "This function takes the following arguments –\n",
    "\n",
    "zeroValue – Initial value to be used for each partition in folding, this value would be used to initialize the accumulator for each partition. we mostly use 0 for integer and Nil for collections.\n",
    "\n",
    "op – an operator used to both accumulate results within a partition and combine results from all partitions\n",
    "\n",
    "#####Points to Note\n",
    "\n",
    "fold() is similar to reduce() except it takes a ‘Zero value‘ as an initial value for each partition.\n",
    "\n",
    "fold() is similar to aggregate() with a difference; fold return type should be the same as this RDD element type whereas aggregation can return any type.\n",
    "    \n",
    "fold() also same as foldByKey() except foldByKey() operates on Pair RDD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aafcc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7fd16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ace60c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.fold(0, op=(lambda acc,data: acc+data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80c0c876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.fold(0, op=(lambda acc, data: max(acc, data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fedd2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.fold(100, op=(lambda acc, data: min(acc, data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc06ba7",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.foldByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "679253b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['filamentA', '100W', 605], ['filamentB', '100W', 683]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc98fd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', 605), ('filamentB', 683)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd = filDataSingleRDD.map(lambda data: (data[0], data[2]))\n",
    "paired_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab279a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('filamentB', 5041), ('filamentA', 4684)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.foldByKey(0, func=(lambda acc, data: acc+data)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f62b17e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentB', 696), ('filamentA', 668)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.foldByKey(0, func=(lambda acc, data: max(acc, data))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8a0979a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentB', 555), ('filamentA', 520)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.foldByKey(1000, func=(lambda acc, data: min(acc, data))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dfb16a",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.foreach\n",
    "A very simple example would be rdd.foreach(print) which would print the value of each row in the RDD but not modify the RDD in any way.\n",
    "In conclusion, Spark foreach() is an action operation of RDD, DataFrame, Dataset which doesn’t have any return type and is used to manipulate the accumulator and write any external data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60adfd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.foreach(f=ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37f7a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.foreach(lambda data: data*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16780368",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.foreach(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "802927c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(iterator):\n",
    "    for x in iterator:\n",
    "        print(x)\n",
    "\n",
    "sc.parallelize([1, 2, 3, 4, 5]).foreachPartition(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9396ccc0",
   "metadata": {},
   "source": [
    "\n",
    "#### pyspark.RDD.getCheckpointFile\n",
    "Gets the name of the file to which this RDD was checkpointed\n",
    "\n",
    "Not defined if RDD is checkpointed locally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "627df800",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.getCheckpointFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed372fe9",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.getResourceProfile\n",
    "The user specified profile or None if none were specified\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e6ea628",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.getResourceProfile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52599b65",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.getStorageLevel\n",
    "Get the RDD’s current storage level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a63c537e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, False, False, False, 1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "954f476c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized 1x Replicated\n"
     ]
    }
   ],
   "source": [
    "print(rdd.getStorageLevel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14065287",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.glom\n",
    "Return an RDD created by coalescing all elements within each partition into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "42a030d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7392430d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6556c6ac",
   "metadata": {},
   "source": [
    "#### groupby\n",
    "Similar to SQL GROUP BY clause, PySpark groupBy() function is used to collect the identical data into groups on DataFrame and perform count, sum, avg, min, max functions on the grouped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fd8271a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(False, [1, 2, 3, 4, 5]), (True, [6, 7, 8, 9, 10])]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.groupBy(lambda data: data>5).mapValues(list).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb9d765d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(False, [1, 2, 3, 4, 5]), (True, [6, 7, 8, 9, 10])]\n"
     ]
    }
   ],
   "source": [
    "data = rdd.groupBy(lambda data: data>5).collect()\n",
    "print([(x, sorted(y)) for x, y in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7b234f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [2, 4, 6, 8, 10]), (1, [1, 3, 5, 7, 9])]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = rdd.groupBy(lambda data: data%2).collect()\n",
    "[(x, sorted(y)) for x,y in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c7a7a50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.groupBy(lambda data: data%2).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9b67a2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['filamentA', '100W', 605], ['filamentB', '100W', 683]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d5dfc7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.groupBy(lambda data: data[0]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4a97dab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentB',\n",
       "  [['filamentB', '100W', 683],\n",
       "   ['filamentB', '100W', 691],\n",
       "   ['filamentB', '200W', 561],\n",
       "   ['filamentB', '100W', 686],\n",
       "   ['filamentB', '200W', 600],\n",
       "   ['filamentB', '100W', 696],\n",
       "   ['filamentB', '200W', 569],\n",
       "   ['filamentB', '200W', 555]]),\n",
       " ('filamentA',\n",
       "  [['filamentA', '100W', 605],\n",
       "   ['filamentA', '200W', 530],\n",
       "   ['filamentA', '100W', 619],\n",
       "   ['filamentA', '200W', 579],\n",
       "   ['filamentA', '200W', 520],\n",
       "   ['filamentA', '100W', 622],\n",
       "   ['filamentA', '100W', 668],\n",
       "   ['filamentA', '200W', 541]])]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.groupBy(lambda data: data[0]).mapValues(list).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f4b9f253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('filamentB', 8), ('filamentA', 8)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.groupBy(lambda data: data[0]).mapValues(len).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64017982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a625e00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7b4e7d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.groupBy(lambda data: data[2]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab31ff64",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.groupByKey\n",
    "Group the values for each key in the RDD into a single sequence. Hash-partitions the resulting RDD with numPartitions partitions.\n",
    "\n",
    "Notes: If you are grouping in order to perform an aggregation (such as a sum or average) over each key, using reduceByKey or aggregateByKey will provide much better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ee2737ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.groupByKey().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c8341546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentB', 696), ('filamentA', 668)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.groupByKey().mapValues(max).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "16bf714a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentB', 555), ('filamentA', 520)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.groupByKey().mapValues(min).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7fcb2c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentB', 5041), ('filamentA', 4684)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.groupByKey().mapValues(sum).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3498f8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentB', 8), ('filamentA', 8)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.groupByKey().mapValues(len).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aa2dd72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentB', [683, 691, 561, 686, 600, 696, 569, 555]),\n",
       " ('filamentA', [605, 530, 619, 579, 520, 622, 668, 541])]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.groupByKey().mapValues(list).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024eeea7",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.groupWith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "54dd973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('a', ([5], [1], [2], [])), ('b', ([6], [4], [], [42]))]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = sc.parallelize([(\"a\", 5), (\"b\", 6)])\n",
    "\n",
    "x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
    "\n",
    "y = sc.parallelize([(\"a\", 2)])\n",
    "\n",
    "z = sc.parallelize([(\"b\", 42)])\n",
    "\n",
    "[(x, tuple(map(list, y))) for x, y in sorted(list(w.groupWith(x, y, z).collect()))]\n",
    "[('a', ([5], [1], [2], [])), ('b', ([6], [4], [], [42]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9d31e2",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.id\n",
    "A unique ID for this RDD (within its SparkContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "28bc033d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3ace058c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.id()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e64434",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.intersection\n",
    " Return the intersection of this RDD and another one. The output will not contain any duplicate elements, even if the input RDDs did.\n",
    "Notes:This method performs a shuffle internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ffbe536f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 11, 15]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([1,2,3,11,15])\n",
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4db40a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b69499f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.intersection(rdd1).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d542e",
   "metadata": {},
   "source": [
    "#### mpyspark.RDD.isCheckpointed\n",
    "Return whether this RDD is checkpointed and materialized, either reliably or locally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fc5e7fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.is_checkpointed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "16a9702b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.is_checkpointed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab118ec",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.isEmpty¶\n",
    " Returns true if and only if the RDD contains no elements at all.\n",
    "\n",
    "Notes: An RDD may be empty even when it has at least 1 partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "55ce4e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sc.parallelize([])\n",
    "s.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5dc51484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.isEmpty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "70e92f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = sc.parallelize([1])\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "79a188c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isEmpty()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac30afd",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.join\n",
    "\n",
    "    Return an RDD containing all pairs of elements with matching keys in self and other.\n",
    "\n",
    "    Each pair of elements will be returned as a (k, (v1, v2)) tuple, where (k, v1) is in self and (k, v2) is in other.\n",
    "\n",
    "    Performs a hash join across the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1f984804",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sc.parallelize([('a',1),('b',1)])\n",
    "y = sc.parallelize([('a',10),('c',10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f8d2d336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', (1, 10))]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.join(y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c45b4",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.keyBy\n",
    "Creates tuples of the elements in this RDD by applying f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "065c89b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (1, 1), (4, 2)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize(range(0,3)).keyBy(lambda x: x*x)\n",
    "x.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e7aeab87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(range(0,3)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3e931282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 11, 15]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d82aa713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (4, 2), (9, 3), (121, 11), (225, 15)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.keyBy(lambda data: data**2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d75eb2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', 605), ('filamentB', 683)]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd = filDataSingleRDD.map(lambda data: (data[0], data[2]))\n",
    "paired_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a1a52716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', ['filamentA', '100W', 605]),\n",
       " ('filamentB', ['filamentB', '100W', 683]),\n",
       " ('filamentB', ['filamentB', '100W', 691]),\n",
       " ('filamentB', ['filamentB', '200W', 561]),\n",
       " ('filamentA', ['filamentA', '200W', 530]),\n",
       " ('filamentA', ['filamentA', '100W', 619]),\n",
       " ('filamentB', ['filamentB', '100W', 686]),\n",
       " ('filamentB', ['filamentB', '200W', 600]),\n",
       " ('filamentB', ['filamentB', '100W', 696]),\n",
       " ('filamentA', ['filamentA', '200W', 579]),\n",
       " ('filamentA', ['filamentA', '200W', 520]),\n",
       " ('filamentA', ['filamentA', '100W', 622]),\n",
       " ('filamentA', ['filamentA', '100W', 668]),\n",
       " ('filamentB', ['filamentB', '200W', 569]),\n",
       " ('filamentB', ['filamentB', '200W', 555]),\n",
       " ('filamentA', ['filamentA', '200W', 541])]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.keyBy(lambda data: data[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2ecc0f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('filamentA', '100W'), ['filamentA', '100W', 605]),\n",
       " (('filamentB', '100W'), ['filamentB', '100W', 683]),\n",
       " (('filamentB', '100W'), ['filamentB', '100W', 691]),\n",
       " (('filamentB', '200W'), ['filamentB', '200W', 561]),\n",
       " (('filamentA', '200W'), ['filamentA', '200W', 530]),\n",
       " (('filamentA', '100W'), ['filamentA', '100W', 619]),\n",
       " (('filamentB', '100W'), ['filamentB', '100W', 686]),\n",
       " (('filamentB', '200W'), ['filamentB', '200W', 600]),\n",
       " (('filamentB', '100W'), ['filamentB', '100W', 696]),\n",
       " (('filamentA', '200W'), ['filamentA', '200W', 579]),\n",
       " (('filamentA', '200W'), ['filamentA', '200W', 520]),\n",
       " (('filamentA', '100W'), ['filamentA', '100W', 622]),\n",
       " (('filamentA', '100W'), ['filamentA', '100W', 668]),\n",
       " (('filamentB', '200W'), ['filamentB', '200W', 569]),\n",
       " (('filamentB', '200W'), ['filamentB', '200W', 555]),\n",
       " (('filamentA', '200W'), ['filamentA', '200W', 541])]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.keyBy(lambda data: (data[0], data[1])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76722db6",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.lookup\n",
    "Return the list of values in the RDD for key key. This operation is done efficiently if the RDD has a known partitioner by only searching the partition that the key maps to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7c647005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = range(10)\n",
    "\n",
    "rdd = sc.parallelize(zip(l, l), 10)\n",
    "\n",
    "rdd.lookup(4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "91e19e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 1),\n",
       " (2, 2),\n",
       " (3, 3),\n",
       " (4, 4),\n",
       " (5, 5),\n",
       " (6, 6),\n",
       " (7, 7),\n",
       " (8, 8),\n",
       " (9, 9)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5a61198d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100W', '200W', '100W', '200W', '200W', '100W', '100W', '200W']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.lookup('filamentA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50245853",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.map\n",
    "Return a new RDD by applying a function to each element of this RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "db975fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 11, 15]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "345682b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 8, 27, 1331, 3375]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.map(lambda data: data **3).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c183268",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.mapPartitions\n",
    "Return a new RDD by applying a function to each partition of this RDD.\n",
    "\n",
    "\n",
    "Similar to map() PySpark mapPartitions() is a narrow transformation operation that applies a function to each partition of the RDD, if you have a DataFrame, you need to convert to RDD in order to use it. mapPartitions() is mainly used to initialize connections once for each partition instead of every row, this is the main difference between map() vs mapPartitions(). It is a narrow transformation as there will not be any data movement/shuffling between partitions to perform the function.\n",
    "\n",
    "Key Points of PySpark MapPartitions():\n",
    "    It is similar to map() operation where the output of mapPartitions() returns the same number of rows as in input RDD.\n",
    "    It is used to improve the performance of the map() when there is a need to do heavy initializations like Database connection.\n",
    "    mapPartitions() applies a heavy initialization to each partition of RDD instead of each element of RDD.\n",
    "    It is a Narrow transformation operation\n",
    "    PySpark DataFrame doesn’t have this operation hence you need to convert DataFrame to RDD to use mapPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9ddf9b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(10),2)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b9ddcd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(v):\n",
    "    yield sum(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "905d0fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10, 35]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.mapPartitions(add).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007efb9c",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.mapValues\n",
    "Pass each value in the key-value pair RDD through a map function without changing the keys; this also retains the original RDD’s partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0a8e3fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', [1]), ('b', [10]), ('a', [133]), ('b', [30])]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([('a',[1]),('b',[10]),('a',[133]),('b',[30])])\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "34fc29dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 1), ('a', 1), ('b', 1)]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.mapValues(len).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "21f4ab46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 10), ('a', 133), ('b', 30)]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.mapValues(sum).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ce7a31f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('b', 40), ('a', 134)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.aggregateByKey(0, seqFunc=(lambda acc,data: acc+ data[0]), combFunc=(lambda data, data2:data+data2)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "34467f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 11, 15]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fdcea55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', (605, 1)),\n",
       " ('filamentB', (683, 1)),\n",
       " ('filamentB', (691, 1)),\n",
       " ('filamentB', (561, 1)),\n",
       " ('filamentA', (530, 1)),\n",
       " ('filamentA', (619, 1)),\n",
       " ('filamentB', (686, 1)),\n",
       " ('filamentB', (600, 1)),\n",
       " ('filamentB', (696, 1)),\n",
       " ('filamentA', (579, 1)),\n",
       " ('filamentA', (520, 1)),\n",
       " ('filamentA', (622, 1)),\n",
       " ('filamentA', (668, 1)),\n",
       " ('filamentB', (569, 1)),\n",
       " ('filamentB', (555, 1)),\n",
       " ('filamentA', (541, 1))]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.mapValues(lambda data: (data,1)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5569ace7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', 605),\n",
       " ('filamentB', 683),\n",
       " ('filamentB', 691),\n",
       " ('filamentB', 561),\n",
       " ('filamentA', 530),\n",
       " ('filamentA', 619),\n",
       " ('filamentB', 686),\n",
       " ('filamentB', 600),\n",
       " ('filamentB', 696),\n",
       " ('filamentA', 579),\n",
       " ('filamentA', 520),\n",
       " ('filamentA', 622),\n",
       " ('filamentA', 668),\n",
       " ('filamentB', 569),\n",
       " ('filamentB', 555),\n",
       " ('filamentA', 541)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e711b5",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.max\n",
    "Find the maximum item in this RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "249b6a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 11, 15]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "60ca4674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "dbcd718a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.4"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d3a68792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4c753776",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1.name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af3f2be",
   "metadata": {},
   "source": [
    "#### PySpark partitionBy() \n",
    "is a function of pyspark.sql.DataFrameWriter class that is used to partition based on one or multiple columns while writing DataFrame to Disk/File system. It creates a sub-directory for each unique value of the partition column.\n",
    "\n",
    "Creating disk level partitioning, speeds up further data reading when you filter by partitioning column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "97b1d99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 1), (2, 2), (3, 3), (4, 4), (2, 2), (4, 4), (1, 1)]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = sc.parallelize([1, 2, 3, 4, 2, 4, 1]).map(lambda x: (x, x))\n",
    "pairs.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "bd3bd018",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = pairs.partitionBy(3).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3d7c89c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 3)]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "79538129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (4, 4), (4, 4), (1, 1)]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c5e30e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(3, 3)], [(1, 1), (4, 4), (4, 4), (1, 1)], [(2, 2), (2, 2)]]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ecd546",
   "metadata": {},
   "source": [
    "#### persist\n",
    "\n",
    "https://sparkbyexamples.com/spark/spark-persistence-storage-levels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "77b49027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import StorageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a75b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a789d997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[235] at readRDDFromFile at PythonRDD.scala:274"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.persist(storageLevel=StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3ed0dd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3b443d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[327] at readRDDFromFile at PythonRDD.scala:274"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.persist(storageLevel=StorageLevel.MEMORY_AND_DISK_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d43d6f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[313] at collect at /tmp/ipykernel_6404/4007458860.py:1"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.persist(storageLevel=StorageLevel.MEMORY_ONLY_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0e879a",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.reduce\n",
    "Reduces the elements of this RDD using the specified commutative and associative binary operator. Currently reduces partitions locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "6ad0e582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.reduce(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "722397d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.reduce(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "adb6013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e9877735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9240f3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9725"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.map(lambda data: data[2]).reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2d249499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.map(lambda data: data[2]).reduce(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b893b710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexRDD.map(lambda data: data[1]).reduce(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5d9e6192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.reduce(lambda data, data2: data+data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c2528",
   "metadata": {},
   "source": [
    "#### PySpark reduceByKey() \n",
    "\n",
    "transformation is used to merge the values of each key using an associative reduce function on PySpark RDD. It is a wider transformation as it shuffles data across multiple partitions and It operates on pair RDD (key/value pair).\n",
    "\n",
    "When reduceByKey() performs, the output will be partitioned by either numPartitions or the default parallelism level. The Default partitioner is hash-partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c0854de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', 605)]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "85bf00c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentB', 5041), ('filamentA', 4684)]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.reduceByKey(add).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b185a910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentB', 5041), ('filamentA', 4684)]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.reduceByKey(lambda data, data2: data+data2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "17a9151b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('filamentB', 696), ('filamentA', 668)]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.reduceByKey(lambda data, data2: max(data, data2)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "99a8674c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentB', 696), ('filamentA', 668)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.reduceByKey(max).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2551238c",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.repartition\n",
    " Return a new RDD that has exactly numPartitions partitions.\n",
    "Can increase or decrease the level of parallelism in this RDD. Internally, this uses a shuffle to redistribute data. If you are decreasing the number of partitions in this RDD, consider using coalesce, which can avoid performing a shuffle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ea588329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = rdd.repartition(3)\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c4664aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = rdd.repartition(1)\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf44299b",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.sample¶\n",
    "\n",
    "    Return a sampled subset of this RDD.\n",
    "\n",
    "    Parameters\n",
    "\n",
    "        withReplacementbool\n",
    "\n",
    "            can elements be sampled multiple times (replaced when sampled out)\n",
    "        fractionfloat\n",
    "\n",
    "            expected size of the sample as a fraction of this RDD’s size without replacement: probability that each element is chosen; fraction must be [0, 1] with replacement: expected number of times each element is chosen; fraction must be >= 0\n",
    "        seedint, optional\n",
    "\n",
    "            seed for the random number generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "33f11517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['filamentA', '100W', 619], ['filamentB', '200W', 555]]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.sample(True, 0.15,220).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d5781b",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.sampleByKey¶\n",
    "\n",
    "    Return a subset of this RDD sampled by key (via stratified sampling). Create a sample of this RDD using variable sampling rates for different keys as specified by fractions, a key to sampling rate map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3f8976c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('filamentB', 561),\n",
       " ('filamentA', 619),\n",
       " ('filamentA', 619),\n",
       " ('filamentB', 696),\n",
       " ('filamentA', 520),\n",
       " ('filamentA', 541)]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.sampleByKey(True,{\"filamentA\": 0.2, \"filamentB\": 0.1}).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9191929",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.setName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "428a5ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd MapPartitionsRDD[432] at coalesce at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.setName('rdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f0849162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rdd'"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d3966b",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.sortBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "15604d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', 605), ('filamentB', 683)]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "12c8ec9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', 605),\n",
       " ('filamentA', 530),\n",
       " ('filamentA', 619),\n",
       " ('filamentA', 579),\n",
       " ('filamentA', 520),\n",
       " ('filamentA', 622),\n",
       " ('filamentA', 668),\n",
       " ('filamentA', 541),\n",
       " ('filamentB', 683),\n",
       " ('filamentB', 691),\n",
       " ('filamentB', 561),\n",
       " ('filamentB', 686),\n",
       " ('filamentB', 600),\n",
       " ('filamentB', 696),\n",
       " ('filamentB', 569),\n",
       " ('filamentB', 555)]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.sortBy(lambda data: data[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "363a99dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', 520),\n",
       " ('filamentA', 530),\n",
       " ('filamentA', 541),\n",
       " ('filamentB', 555),\n",
       " ('filamentB', 561),\n",
       " ('filamentB', 569),\n",
       " ('filamentA', 579),\n",
       " ('filamentB', 600),\n",
       " ('filamentA', 605),\n",
       " ('filamentA', 619),\n",
       " ('filamentA', 622),\n",
       " ('filamentA', 668),\n",
       " ('filamentB', 683),\n",
       " ('filamentB', 686),\n",
       " ('filamentB', 691),\n",
       " ('filamentB', 696)]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.sortBy(lambda data: data[1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "97811636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 11, 15]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.sortBy(lambda data: data).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "79951093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 11, 3, 2, 1]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.sortBy(lambda data: -data).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc5ea3",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.sortByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f6cb9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = sc.parallelize([('a',10),('b',7),('a',10),('b',7),('a',10),('a',7),('d',10),('c',7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "0c32f175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 10),\n",
       " ('a', 10),\n",
       " ('a', 10),\n",
       " ('a', 7),\n",
       " ('b', 7),\n",
       " ('b', 7),\n",
       " ('c', 7),\n",
       " ('d', 10)]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.sortByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "fec8bdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('filamentA', '100W'), 605),\n",
       " (('filamentA', '100W'), 619),\n",
       " (('filamentA', '100W'), 622),\n",
       " (('filamentA', '100W'), 668),\n",
       " (('filamentA', '200W'), 530),\n",
       " (('filamentA', '200W'), 579),\n",
       " (('filamentA', '200W'), 520),\n",
       " (('filamentA', '200W'), 541),\n",
       " (('filamentB', '100W'), 683),\n",
       " (('filamentB', '100W'), 691),\n",
       " (('filamentB', '100W'), 686),\n",
       " (('filamentB', '100W'), 696),\n",
       " (('filamentB', '200W'), 561),\n",
       " (('filamentB', '200W'), 600),\n",
       " (('filamentB', '200W'), 569),\n",
       " (('filamentB', '200W'), 555)]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexRDD.sortByKey().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4bfa52",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "8caa279a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('a', [1]), ('b', [10]), ('a', [133]), ('b', [30])]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "75759eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 11, 15]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d6420266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count: 5, mean: 6.4, stdev: 5.571355310873647, max: 15.0, min: 1.0)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660cee68",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.subtract\n",
    "Return each value in self that is not contained in other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "abbcdec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 4), ('b', 5)]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([(\"a\", 1), (\"b\", 4), (\"b\", 5), (\"a\", 3)])\n",
    "y = sc.parallelize([(\"a\", 3), (\"c\", None)])\n",
    "\n",
    "sorted(x.subtract(y).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5928538c",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.subtractByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "1232ac4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 4), ('b', 5)]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.subtractByKey(y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd64daa",
   "metadata": {},
   "source": [
    "pyspark.RDD.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "aeb4d5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f8157",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.take¶\n",
    "\n",
    "Take the first num elements of the RDD.\n",
    "\n",
    "It works by first scanning one partition, and use the results from that partition to estimate the number of additional partitions needed to satisfy the limit.\n",
    "\n",
    "Translated from the Scala implementation in RDD#take().\n",
    "\n",
    "Notes :This method should only be used if the resulting array is expected to be small, as all the data is loaded into the driver’s memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "382ea084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', [1]), ('b', [10])]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e5365",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.takeOrdered\n",
    "\n",
    "Get the N elements from an RDD ordered in ascending order or as specified by the optional key function.\n",
    "\n",
    "Notes: This method should only be used if the resulting array is expected to be small, as all the data is loaded into the driver’s memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "3731804c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([10, 1, 2, 9, 3, 4, 5, 6, 7]).takeOrdered(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "d2ed760b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 9, 7, 6, 5, 4]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([10, 1, 2, 9, 3, 4, 5, 6, 7], 2).takeOrdered(6, key=lambda x: -x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1f6a2c",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.top\n",
    "\n",
    "Get the top N elements from an RDD.\n",
    "\n",
    "Notes: This method should only be used if the resulting array is expected to be small, as all the data is loaded into the driver’s memory.\n",
    "\n",
    "It returns the list sorted in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "e95b28d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['filamentB', '200W', 600], ['filamentB', '200W', 569]]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.top(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "6d0cc54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.top(2,key=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea4ba6",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.unpersist¶\n",
    "Mark the RDD as non-persistent, and remove all blocks for it from memory and disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b586181e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd MapPartitionsRDD[432] at coalesce at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "05d68b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[313] at collect at /tmp/ipykernel_6404/4007458860.py:1"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa364b0",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.values\n",
    "Return an RDD with the values of each tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "2860e69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[605,\n",
       " 683,\n",
       " 691,\n",
       " 561,\n",
       " 530,\n",
       " 619,\n",
       " 686,\n",
       " 600,\n",
       " 696,\n",
       " 579,\n",
       " 520,\n",
       " 622,\n",
       " 668,\n",
       " 569,\n",
       " 555,\n",
       " 541]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_rdd.values().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "cda658f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [10], [133], [30]]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.values().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caab4e7",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.zip\n",
    "\n",
    "    Zips this RDD with another one, returning key-value pairs with the first element in each RDD second element in each RDD, etc. Assumes that the two RDDs have the same number of partitions and the same number of elements in each partition (e.g. one was made through a map on the other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a9946b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1000), (1, 1001), (2, 1002), (3, 1003), (4, 1004)]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize(range(0,5))\n",
    "\n",
    "y = sc.parallelize(range(1000, 1005))\n",
    "\n",
    "x.zip(y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf7536b",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.zipWithIndex\n",
    "\n",
    "Zips this RDD with its element indices.\n",
    "\n",
    "The ordering is first based on the partition index and then the ordering of items within each partition. So the first item in the first partition gets index 0, and the last item in the last partition receives the largest index.\n",
    "\n",
    "This method needs to trigger a spark job when this RDD contains more than one partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "f1441ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0), ('b', 1), ('c', 2), ('d', 3)]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([\"a\", \"b\", \"c\", \"d\"], 3).zipWithIndex().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "d8278a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['filamentA', '100W', 605], 0),\n",
       " (['filamentB', '100W', 683], 1),\n",
       " (['filamentB', '100W', 691], 2),\n",
       " (['filamentB', '200W', 561], 3),\n",
       " (['filamentA', '200W', 530], 4),\n",
       " (['filamentA', '100W', 619], 5),\n",
       " (['filamentB', '100W', 686], 6),\n",
       " (['filamentB', '200W', 600], 7),\n",
       " (['filamentB', '100W', 696], 8),\n",
       " (['filamentA', '200W', 579], 9),\n",
       " (['filamentA', '200W', 520], 10),\n",
       " (['filamentA', '100W', 622], 11),\n",
       " (['filamentA', '100W', 668], 12),\n",
       " (['filamentB', '200W', 569], 13),\n",
       " (['filamentB', '200W', 555], 14),\n",
       " (['filamentA', '200W', 541], 15)]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filDataSingleRDD.zipWithIndex().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf98be5",
   "metadata": {},
   "source": [
    "#### pyspark.RDD.zipWithUniqueId¶\n",
    "\n",
    "Zips this RDD with generated unique Long ids.\n",
    "\n",
    "Items in the kth partition will get ids k, n+k, 2*n+k, …, where n is the number of partitions. So there may exist gaps, but this method won’t trigger a spark job, which is different from zipWithIndex()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f381c219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0), ('b', 1), ('c', 4), ('d', 2), ('e', 5)]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([\"a\", \"b\", \"c\", \"d\", \"e\"], 3).zipWithUniqueId().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e3479334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['filamentA', '100W', 605], 0),\n",
       " (['filamentB', '100W', 683], 2),\n",
       " (['filamentB', '100W', 691], 4),\n",
       " (['filamentB', '200W', 561], 6),\n",
       " (['filamentA', '200W', 530], 8),\n",
       " (['filamentA', '100W', 619], 10),\n",
       " (['filamentB', '100W', 686], 12),\n",
       " (['filamentB', '200W', 600], 14),\n",
       " (['filamentB', '100W', 696], 1),\n",
       " (['filamentA', '200W', 579], 3),\n",
       " (['filamentA', '200W', 520], 5),\n",
       " (['filamentA', '100W', 622], 7),\n",
       " (['filamentA', '100W', 668], 9),\n",
       " (['filamentB', '200W', 569], 11),\n",
       " (['filamentB', '200W', 555], 13),\n",
       " (['filamentA', '200W', 541], 15)]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 11:48:30 WARN DataStreamer: Exception for BP-241050457-127.0.0.1-1670841776195:blk_1073744969_4151\n",
      "java.net.SocketTimeoutException: 65000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:56260 remote=/127.0.0.1:9866]\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)\n",
      "\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n",
      "\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n",
      "\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)\n",
      "\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n",
      "\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:519)\n",
      "\tat org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run(DataStreamer.java:1137)\n",
      "22/12/27 11:48:37 WARN HeartbeatReceiver: Removing executor 1 with no recent heartbeats: 65784915 ms exceeds timeout 120000 ms\n",
      "22/12/27 11:48:38 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 11:48:39 ERROR YarnScheduler: Lost executor 1 on audacious: Executor heartbeat timed out after 65784915 ms\n",
      "22/12/27 11:48:39 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 11:48:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_327_0 !\n",
      "22/12/27 11:48:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_235_0 !\n",
      "22/12/27 11:48:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_327_1 !\n",
      "22/12/27 11:48:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_235_1 !\n",
      "22/12/27 11:48:39 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 11:48:47 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 11:48:47 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:13:36 WARN HeartbeatReceiver: Removing executor 2 with no recent heartbeats: 170315 ms exceeds timeout 120000 ms\n",
      "22/12/27 15:15:36 ERROR Utils: Uncaught exception in thread kill-executor-thread\n",
      "org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)\n",
      "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.killExecutors(CoarseGrainedSchedulerBackend.scala:890)\n",
      "\tat org.apache.spark.SparkContext.killAndReplaceExecutor(SparkContext.scala:1825)\n",
      "\tat org.apache.spark.HeartbeatReceiver$$anon$2.$anonfun$run$2(HeartbeatReceiver.scala:214)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)\n",
      "\tat org.apache.spark.HeartbeatReceiver$$anon$2.run(HeartbeatReceiver.scala:211)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:293)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\t... 10 more\n",
      "22/12/27 15:15:36 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending KillExecutors(List(2)) to AM was unsuccessful\n",
      "org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from /192.168.87.202:60228 in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat scala.util.Failure.recover(Try.scala:234)\n",
      "\tat scala.concurrent.Future.$anonfun$recover$1(Future.scala:395)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.tryFailure(Promise.scala:112)\n",
      "\tat scala.concurrent.Promise.tryFailure$(Promise.scala:112)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:264)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from /192.168.87.202:60228 in 120 seconds\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:265)\n",
      "\t... 7 more\n",
      "22/12/27 15:15:36 WARN NettyRpcEnv: Ignored failure: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from /192.168.87.202:60228 in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:17:36 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:17:46 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:17:56 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:18:06 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:18:16 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:18:26 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:18:36 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:18:46 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:18:56 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:19:06 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:19:11 WARN TransportResponseHandler: Ignoring response for RPC 5394702714831775751 from /192.168.87.202:60228 (47 bytes) since it is not outstanding\n",
      "22/12/27 15:19:12 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:19:12 ERROR YarnScheduler: Lost executor 2 on audacious: Container container_1672038063177_0001_01_000003 exited from explicit termination request.\n",
      "22/12/27 15:19:12 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:19:16 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:19:16 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:32:58 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 30 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:32:59 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 31 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:00 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 32 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:01 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 33 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:02 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 34 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:03 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 35 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:04 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 36 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:05 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:33:05 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /192.168.87.202:60228 is closed\n",
      "22/12/27 15:33:05 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to get executor loss reason for executor id 3 at RPC address 192.168.87.202:43590, but got no response. Marking as agent lost.\n",
      "java.io.IOException: Connection from /192.168.87.202:60228 closed\n",
      "\tat org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:147)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)\n",
      "\tat io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)\n",
      "\tat io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)\n",
      "\tat io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)\n",
      "\tat io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:813)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/12/27 15:33:05 ERROR YarnScheduler: Lost executor 3 on audacious: Executor Process Lost\n",
      "22/12/27 15:33:05 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:33:05 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 37 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:06 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 38 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:07 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 39 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:08 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 40 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:09 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 41 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:10 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 42 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:11 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 43 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:12 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 44 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:13 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 45 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:14 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 46 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:15 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 47 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:16 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 48 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:17 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 49 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:18 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 50 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:19 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 51 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:20 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 52 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:21 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 53 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:22 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 54 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:23 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 55 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:24 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 56 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:25 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 57 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:26 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 58 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:27 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 59 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:28 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 60 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:29 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 61 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:30 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 62 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:31 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 63 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:32 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 64 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:33 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 65 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:34 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 66 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:35 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 67 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:36 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 68 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:37 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 69 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n",
      "22/12/27 15:33:38 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 70 seconds.  Will retry shortly ...\n",
      "java.net.ConnectException: Call From audacious/192.168.87.202 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "\tat sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)\n",
      "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:828)\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1502)\n",
      "\t... 20 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:40 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 71 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 0 needs additional 606 blocks to reach the threshold 0.9990 of total blocks 607.\n",
      "The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/12/27 15:33:41 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 73 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 0 needs additional 606 blocks to reach the threshold 0.9990 of total blocks 607.\n",
      "The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/12/27 15:33:42 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 74 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 0 needs additional 606 blocks to reach the threshold 0.9990 of total blocks 607.\n",
      "The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:43 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 75 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 0 needs additional 606 blocks to reach the threshold 0.9990 of total blocks 607.\n",
      "The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/12/27 15:33:44 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 76 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 29 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/12/27 15:33:45 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 77 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 28 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:46 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 78 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 27 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/12/27 15:33:47 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 79 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 26 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/12/27 15:33:48 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 80 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 25 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:49 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 81 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 24 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/12/27 15:33:50 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 82 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 23 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/12/27 15:33:51 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 83 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 22 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:52 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 84 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 21 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/12/27 15:33:53 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 85 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 20 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/12/27 15:33:54 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 86 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 19 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/27 15:33:55 ERROR Client: Application application_1672038063177_0001 not found.\n",
      "22/12/27 15:33:55 WARN Client: Failed to cleanup staging dir hdfs://localhost:9000/user/audacious/.sparkStaging/application_1672038063177_0001\n",
      "org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/audacious/.sparkStaging/application_1672038063177_0001. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 18 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3265)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1128)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:725)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)\n",
      "\tat org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1664)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:992)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:989)\n",
      "\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:999)\n",
      "\tat org.apache.spark.deploy.yarn.Client.cleanupStagingDirInternal$1(Client.scala:248)\n",
      "\tat org.apache.spark.deploy.yarn.Client.cleanupStagingDir(Client.scala:257)\n",
      "\tat org.apache.spark.deploy.yarn.Client.monitorApplication(Client.scala:1170)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:118)\n",
      "Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot delete /user/audacious/.sparkStaging/application_1672038063177_0001. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 18 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3265)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1128)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:725)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.delete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:655)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.delete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1662)\n",
      "\t... 8 more\n",
      "22/12/27 15:33:55 ERROR YarnClientSchedulerBackend: YARN application has exited unexpectedly with state KILLED! Check the YARN application logs for more details.\n",
      "22/12/27 15:33:55 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception\n",
      "java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n",
      "22/12/27 15:33:55 WARN LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-104603192_14] for 87 seconds.  Will retry shortly ...\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-104603192_14. Name node is in safe mode.\n",
      "The reported blocks 607 has reached the threshold 0.9990 of total blocks 607. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 18 seconds. NamenodeHostName:localhost\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4019)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:1167)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:813)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1558)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1455)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy33.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:748)\n",
      "\tat sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy34.renewLease(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:596)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/12/27 15:33:55 ERROR TransportClient: Failed to send RPC RPC 8619744361434999048 to /192.168.87.202:60228: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/12/27 15:33:55 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(Map(),Map(),Map(),Set()) to AM was unsuccessful\n",
      "java.io.IOException: Failed to send RPC RPC 8619744361434999048 to /192.168.87.202:60228: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:999)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:860)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/12/27 15:33:55 ERROR Utils: Uncaught exception in thread YARN application state monitor\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.requestTotalExecutors(CoarseGrainedSchedulerBackend.scala:789)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnSchedulerBackend.stop(YarnSchedulerBackend.scala:114)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.stop(YarnClientSchedulerBackend.scala:178)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:931)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2785)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$11(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:125)\n",
      "Caused by: java.io.IOException: Failed to send RPC RPC 8619744361434999048 to /192.168.87.202:60228: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:999)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:860)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/12/27 15:33:55 ERROR Utils: Uncaught exception in thread YARN application state monitor\n",
      "java.lang.IllegalArgumentException: Self-suppression not permitted\n",
      "\tat java.lang.Throwable.addSuppressed(Throwable.java:1072)\n",
      "\tat java.io.FilterOutputStream.close(FilterOutputStream.java:159)\n",
      "\tat sun.nio.cs.StreamEncoder.implClose(StreamEncoder.java:320)\n",
      "\tat sun.nio.cs.StreamEncoder.close(StreamEncoder.java:149)\n",
      "\tat java.io.OutputStreamWriter.close(OutputStreamWriter.java:233)\n",
      "\tat java.io.PrintWriter.close(PrintWriter.java:339)\n",
      "\tat org.apache.spark.deploy.history.EventLogFileWriter.$anonfun$closeWriter$1(EventLogFileWriters.scala:127)\n",
      "\tat org.apache.spark.deploy.history.EventLogFileWriter.$anonfun$closeWriter$1$adapted(EventLogFileWriters.scala:127)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.deploy.history.EventLogFileWriter.closeWriter(EventLogFileWriters.scala:127)\n",
      "\tat org.apache.spark.deploy.history.SingleEventLogFileWriter.stop(EventLogFileWriters.scala:237)\n",
      "\tat org.apache.spark.scheduler.EventLoggingListener.stop(EventLoggingListener.scala:283)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$17(SparkContext.scala:2115)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$17$adapted(SparkContext.scala:2115)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$16(SparkContext.scala:2115)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2115)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:125)\n",
      "Caused by: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-e7dcc0b2-0f10-46a2-9872-6f61756e1ab0,DISK]] are bad. Aborting...\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1609)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1543)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)\n"
     ]
    }
   ],
   "source": [
    "filDataSingleRDD.zipWithUniqueId().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90034de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
